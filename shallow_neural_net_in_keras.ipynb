{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow Net in KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a shallow neural network to classify MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set seed reprodicibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9,\n",
       "       1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9,\n",
       "       8, 5, 9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0,\n",
       "       0, 1, 7, 1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7,\n",
       "       4, 6, 8, 0, 7, 8, 3], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  13,  25, 100, 122,   7,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         33, 151, 208, 252, 252, 252, 146,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 152,\n",
       "        244, 252, 253, 224, 211, 252, 232,  40,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  15, 152, 239, 252,\n",
       "        252, 252, 216,  31,  37, 252, 252,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  96, 252, 252, 252,\n",
       "        252, 217,  29,   0,  37, 252, 252,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 181, 252, 252, 220,\n",
       "        167,  30,   0,   0,  77, 252, 252,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  26, 128,  58,  22,\n",
       "          0,   0,   0,   0, 100, 252, 252,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 157, 252, 252,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        110, 121, 122, 121, 202, 252, 194,   3,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  53, 179,\n",
       "        253, 253, 255, 253, 253, 228,  35,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   5,  54, 227, 252, 243,\n",
       "        228, 170, 242, 252, 252, 231, 117,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   6,  78, 252, 252, 125,  59,\n",
       "          0,  18, 208, 252, 252, 252, 252,  87,   7,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   5, 135, 252, 252, 180,  16,   0,\n",
       "         21, 203, 253, 247, 129, 173, 252, 252, 184,  66,  49,  49,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3, 136, 252, 241, 106,  17,   0,  53,\n",
       "        200, 252, 216,  65,   0,  14,  72, 163, 241, 252, 252, 223,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 105, 252, 242,  88,  18,  73, 170, 244,\n",
       "        252, 126,  29,   0,   0,   0,   0,   0,  89, 180, 180,  37,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 231, 252, 245, 205, 216, 252, 252, 252,\n",
       "        124,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 207, 252, 252, 252, 252, 178, 116,  36,\n",
       "          4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  13,  93, 143, 121,  23,   6,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784).astype('float32')\n",
    "X_test = X_test.reshape(10000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design neural network architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=optimizers.SGD(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0917 - acc: 0.1290 - val_loss: 0.0913 - val_acc: 0.1444\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0910 - acc: 0.1461 - val_loss: 0.0907 - val_acc: 0.1667\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0904 - acc: 0.1680 - val_loss: 0.0902 - val_acc: 0.1857\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0899 - acc: 0.1875 - val_loss: 0.0897 - val_acc: 0.1998\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0895 - acc: 0.1998 - val_loss: 0.0893 - val_acc: 0.2092\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0891 - acc: 0.2073 - val_loss: 0.0889 - val_acc: 0.2116\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0887 - acc: 0.2119 - val_loss: 0.0885 - val_acc: 0.2132\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0884 - acc: 0.2159 - val_loss: 0.0882 - val_acc: 0.2170\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0880 - acc: 0.2217 - val_loss: 0.0878 - val_acc: 0.2275\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0877 - acc: 0.2437 - val_loss: 0.0875 - val_acc: 0.2637\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0873 - acc: 0.2789 - val_loss: 0.0871 - val_acc: 0.3036\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0870 - acc: 0.3120 - val_loss: 0.0868 - val_acc: 0.3283\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0867 - acc: 0.3327 - val_loss: 0.0864 - val_acc: 0.3481\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0863 - acc: 0.3494 - val_loss: 0.0861 - val_acc: 0.3613\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0859 - acc: 0.3600 - val_loss: 0.0857 - val_acc: 0.3695\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0856 - acc: 0.3678 - val_loss: 0.0853 - val_acc: 0.3748\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0852 - acc: 0.3741 - val_loss: 0.0849 - val_acc: 0.3826\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0848 - acc: 0.3792 - val_loss: 0.0846 - val_acc: 0.3857\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0844 - acc: 0.3840 - val_loss: 0.0842 - val_acc: 0.3884\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0840 - acc: 0.3883 - val_loss: 0.0837 - val_acc: 0.3919\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0836 - acc: 0.3910 - val_loss: 0.0833 - val_acc: 0.3957\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0832 - acc: 0.3947 - val_loss: 0.0829 - val_acc: 0.4000\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0828 - acc: 0.3991 - val_loss: 0.0825 - val_acc: 0.4036\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0823 - acc: 0.4014 - val_loss: 0.0820 - val_acc: 0.4073\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0819 - acc: 0.4057 - val_loss: 0.0816 - val_acc: 0.4105\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0815 - acc: 0.4090 - val_loss: 0.0811 - val_acc: 0.4131\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0810 - acc: 0.4138 - val_loss: 0.0807 - val_acc: 0.4166\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0805 - acc: 0.4175 - val_loss: 0.0802 - val_acc: 0.4193\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0801 - acc: 0.4218 - val_loss: 0.0797 - val_acc: 0.4223\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0796 - acc: 0.4254 - val_loss: 0.0792 - val_acc: 0.4273\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0791 - acc: 0.4303 - val_loss: 0.0787 - val_acc: 0.4316\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0786 - acc: 0.4355 - val_loss: 0.0782 - val_acc: 0.4379\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0781 - acc: 0.4397 - val_loss: 0.0777 - val_acc: 0.4433\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0776 - acc: 0.4451 - val_loss: 0.0772 - val_acc: 0.4474\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0771 - acc: 0.4491 - val_loss: 0.0767 - val_acc: 0.4515\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0766 - acc: 0.4542 - val_loss: 0.0762 - val_acc: 0.4572\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 2s - loss: 0.0761 - acc: 0.4589 - val_loss: 0.0757 - val_acc: 0.4621\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0756 - acc: 0.4638 - val_loss: 0.0751 - val_acc: 0.4662\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0751 - acc: 0.4691 - val_loss: 0.0746 - val_acc: 0.4723\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0746 - acc: 0.4739 - val_loss: 0.0741 - val_acc: 0.4765\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0740 - acc: 0.4787 - val_loss: 0.0736 - val_acc: 0.4818\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0735 - acc: 0.4846 - val_loss: 0.0731 - val_acc: 0.4869\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0730 - acc: 0.4897 - val_loss: 0.0725 - val_acc: 0.4915\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0725 - acc: 0.4944 - val_loss: 0.0720 - val_acc: 0.4964\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0720 - acc: 0.4995 - val_loss: 0.0715 - val_acc: 0.5025\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0715 - acc: 0.5058 - val_loss: 0.0710 - val_acc: 0.5070\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 2s - loss: 0.0709 - acc: 0.5096 - val_loss: 0.0705 - val_acc: 0.5125\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0704 - acc: 0.5153 - val_loss: 0.0699 - val_acc: 0.5173\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0699 - acc: 0.5196 - val_loss: 0.0694 - val_acc: 0.5223\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0694 - acc: 0.5243 - val_loss: 0.0689 - val_acc: 0.5259\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0689 - acc: 0.5289 - val_loss: 0.0684 - val_acc: 0.5310\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0684 - acc: 0.5334 - val_loss: 0.0679 - val_acc: 0.5371\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0679 - acc: 0.5382 - val_loss: 0.0674 - val_acc: 0.5422\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0674 - acc: 0.5427 - val_loss: 0.0669 - val_acc: 0.5470\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0670 - acc: 0.5471 - val_loss: 0.0664 - val_acc: 0.5521\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 2s - loss: 0.0665 - acc: 0.5516 - val_loss: 0.0659 - val_acc: 0.5567\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0660 - acc: 0.5561 - val_loss: 0.0655 - val_acc: 0.5604\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0655 - acc: 0.5606 - val_loss: 0.0650 - val_acc: 0.5650\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0651 - acc: 0.5639 - val_loss: 0.0645 - val_acc: 0.5690\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0646 - acc: 0.5686 - val_loss: 0.0640 - val_acc: 0.5733\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0641 - acc: 0.5736 - val_loss: 0.0636 - val_acc: 0.5773\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0637 - acc: 0.5781 - val_loss: 0.0631 - val_acc: 0.5817\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0632 - acc: 0.5824 - val_loss: 0.0627 - val_acc: 0.5870\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s - loss: 0.0628 - acc: 0.5864 - val_loss: 0.0622 - val_acc: 0.5912\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0623 - acc: 0.5907 - val_loss: 0.0618 - val_acc: 0.5964\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0619 - acc: 0.5945 - val_loss: 0.0613 - val_acc: 0.6019\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0615 - acc: 0.5979 - val_loss: 0.0609 - val_acc: 0.6053\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0610 - acc: 0.6015 - val_loss: 0.0605 - val_acc: 0.6083\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0606 - acc: 0.6057 - val_loss: 0.0600 - val_acc: 0.6117\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0602 - acc: 0.6089 - val_loss: 0.0596 - val_acc: 0.6150\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0598 - acc: 0.6123 - val_loss: 0.0592 - val_acc: 0.6184\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0594 - acc: 0.6155 - val_loss: 0.0588 - val_acc: 0.6215\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0590 - acc: 0.6191 - val_loss: 0.0584 - val_acc: 0.6242\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0586 - acc: 0.6226 - val_loss: 0.0580 - val_acc: 0.6268\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0582 - acc: 0.6258 - val_loss: 0.0576 - val_acc: 0.6290\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0578 - acc: 0.6286 - val_loss: 0.0572 - val_acc: 0.6327\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0574 - acc: 0.6318 - val_loss: 0.0568 - val_acc: 0.6357\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0570 - acc: 0.6348 - val_loss: 0.0564 - val_acc: 0.6386\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0566 - acc: 0.6373 - val_loss: 0.0560 - val_acc: 0.6420\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0562 - acc: 0.6407 - val_loss: 0.0556 - val_acc: 0.6446\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0559 - acc: 0.6432 - val_loss: 0.0553 - val_acc: 0.6473\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0555 - acc: 0.6461 - val_loss: 0.0549 - val_acc: 0.6510\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0551 - acc: 0.6491 - val_loss: 0.0545 - val_acc: 0.6546\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0548 - acc: 0.6515 - val_loss: 0.0542 - val_acc: 0.6573\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0544 - acc: 0.6542 - val_loss: 0.0538 - val_acc: 0.6589\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0541 - acc: 0.6563 - val_loss: 0.0534 - val_acc: 0.6621\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0537 - acc: 0.6587 - val_loss: 0.0531 - val_acc: 0.6657\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0534 - acc: 0.6606 - val_loss: 0.0527 - val_acc: 0.6677\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0530 - acc: 0.6631 - val_loss: 0.0524 - val_acc: 0.6697\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 2s - loss: 0.0527 - acc: 0.6653 - val_loss: 0.0520 - val_acc: 0.6730\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 2s - loss: 0.0523 - acc: 0.6676 - val_loss: 0.0517 - val_acc: 0.6744\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0520 - acc: 0.6694 - val_loss: 0.0514 - val_acc: 0.6764\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0517 - acc: 0.6715 - val_loss: 0.0510 - val_acc: 0.6786\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0514 - acc: 0.6737 - val_loss: 0.0507 - val_acc: 0.6814\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0510 - acc: 0.6758 - val_loss: 0.0504 - val_acc: 0.6831\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0507 - acc: 0.6781 - val_loss: 0.0501 - val_acc: 0.6851\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0504 - acc: 0.6801 - val_loss: 0.0497 - val_acc: 0.6876\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0501 - acc: 0.6818 - val_loss: 0.0494 - val_acc: 0.6900\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0498 - acc: 0.6840 - val_loss: 0.0491 - val_acc: 0.6926\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0495 - acc: 0.6862 - val_loss: 0.0488 - val_acc: 0.6950\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0492 - acc: 0.6884 - val_loss: 0.0485 - val_acc: 0.6966\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0489 - acc: 0.6905 - val_loss: 0.0482 - val_acc: 0.6988\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0486 - acc: 0.6925 - val_loss: 0.0479 - val_acc: 0.7006\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0483 - acc: 0.6947 - val_loss: 0.0476 - val_acc: 0.7042\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0480 - acc: 0.6969 - val_loss: 0.0473 - val_acc: 0.7057\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0477 - acc: 0.6995 - val_loss: 0.0470 - val_acc: 0.7073\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0474 - acc: 0.7021 - val_loss: 0.0467 - val_acc: 0.7096\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0471 - acc: 0.7039 - val_loss: 0.0464 - val_acc: 0.7123\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0468 - acc: 0.7064 - val_loss: 0.0461 - val_acc: 0.7147\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0465 - acc: 0.7089 - val_loss: 0.0459 - val_acc: 0.7163\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0463 - acc: 0.7115 - val_loss: 0.0456 - val_acc: 0.7191\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0460 - acc: 0.7149 - val_loss: 0.0453 - val_acc: 0.7226\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0457 - acc: 0.7167 - val_loss: 0.0450 - val_acc: 0.7267\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0455 - acc: 0.7197 - val_loss: 0.0448 - val_acc: 0.7294\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0452 - acc: 0.7222 - val_loss: 0.0445 - val_acc: 0.7317\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0449 - acc: 0.7245 - val_loss: 0.0442 - val_acc: 0.7334\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0447 - acc: 0.7271 - val_loss: 0.0440 - val_acc: 0.7361\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0444 - acc: 0.7290 - val_loss: 0.0437 - val_acc: 0.7388\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0442 - acc: 0.7319 - val_loss: 0.0434 - val_acc: 0.7423\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0439 - acc: 0.7350 - val_loss: 0.0432 - val_acc: 0.7444\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0437 - acc: 0.7371 - val_loss: 0.0429 - val_acc: 0.7469\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0434 - acc: 0.7389 - val_loss: 0.0427 - val_acc: 0.7494\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0432 - acc: 0.7410 - val_loss: 0.0424 - val_acc: 0.7527\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0429 - acc: 0.7439 - val_loss: 0.0422 - val_acc: 0.7554\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0427 - acc: 0.7462 - val_loss: 0.0419 - val_acc: 0.7565\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0424 - acc: 0.7479 - val_loss: 0.0417 - val_acc: 0.7578\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s - loss: 0.0422 - acc: 0.7504 - val_loss: 0.0415 - val_acc: 0.7598\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0420 - acc: 0.7522 - val_loss: 0.0412 - val_acc: 0.7621\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0417 - acc: 0.7548 - val_loss: 0.0410 - val_acc: 0.7639\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0415 - acc: 0.7570 - val_loss: 0.0408 - val_acc: 0.7655\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0413 - acc: 0.7596 - val_loss: 0.0405 - val_acc: 0.7672\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0410 - acc: 0.7612 - val_loss: 0.0403 - val_acc: 0.7692\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0408 - acc: 0.7633 - val_loss: 0.0401 - val_acc: 0.7705\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0406 - acc: 0.7651 - val_loss: 0.0398 - val_acc: 0.7730\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0404 - acc: 0.7671 - val_loss: 0.0396 - val_acc: 0.7751\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0402 - acc: 0.7692 - val_loss: 0.0394 - val_acc: 0.7770\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0399 - acc: 0.7712 - val_loss: 0.0392 - val_acc: 0.7785\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0397 - acc: 0.7734 - val_loss: 0.0390 - val_acc: 0.7800\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0395 - acc: 0.7755 - val_loss: 0.0388 - val_acc: 0.7817\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0393 - acc: 0.7771 - val_loss: 0.0385 - val_acc: 0.7834\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0391 - acc: 0.7795 - val_loss: 0.0383 - val_acc: 0.7855\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0389 - acc: 0.7814 - val_loss: 0.0381 - val_acc: 0.7875\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0387 - acc: 0.7832 - val_loss: 0.0379 - val_acc: 0.7902\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0385 - acc: 0.7854 - val_loss: 0.0377 - val_acc: 0.7922\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0383 - acc: 0.7873 - val_loss: 0.0375 - val_acc: 0.7941\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0381 - acc: 0.7892 - val_loss: 0.0373 - val_acc: 0.7964\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0379 - acc: 0.7914 - val_loss: 0.0371 - val_acc: 0.7996\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0377 - acc: 0.7932 - val_loss: 0.0369 - val_acc: 0.8007\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0375 - acc: 0.7949 - val_loss: 0.0367 - val_acc: 0.8024\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0373 - acc: 0.7966 - val_loss: 0.0365 - val_acc: 0.8039\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0371 - acc: 0.7987 - val_loss: 0.0363 - val_acc: 0.8064\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0369 - acc: 0.8009 - val_loss: 0.0361 - val_acc: 0.8088\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0367 - acc: 0.8027 - val_loss: 0.0359 - val_acc: 0.8113\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0365 - acc: 0.8045 - val_loss: 0.0357 - val_acc: 0.8136\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0364 - acc: 0.8061 - val_loss: 0.0356 - val_acc: 0.8148\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0362 - acc: 0.8077 - val_loss: 0.0354 - val_acc: 0.8168\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0360 - acc: 0.8090 - val_loss: 0.0352 - val_acc: 0.8186\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0358 - acc: 0.8104 - val_loss: 0.0350 - val_acc: 0.8207\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0356 - acc: 0.8121 - val_loss: 0.0348 - val_acc: 0.8220\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0355 - acc: 0.8134 - val_loss: 0.0346 - val_acc: 0.8242\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0353 - acc: 0.8155 - val_loss: 0.0345 - val_acc: 0.8256\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0351 - acc: 0.8165 - val_loss: 0.0343 - val_acc: 0.8271\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0349 - acc: 0.8180 - val_loss: 0.0341 - val_acc: 0.8288\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0348 - acc: 0.8193 - val_loss: 0.0339 - val_acc: 0.8303\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0346 - acc: 0.8209 - val_loss: 0.0338 - val_acc: 0.8309\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0344 - acc: 0.8225 - val_loss: 0.0336 - val_acc: 0.8326\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0343 - acc: 0.8238 - val_loss: 0.0334 - val_acc: 0.8334\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0341 - acc: 0.8250 - val_loss: 0.0333 - val_acc: 0.8351\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0339 - acc: 0.8261 - val_loss: 0.0331 - val_acc: 0.8370\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0338 - acc: 0.8273 - val_loss: 0.0329 - val_acc: 0.8379\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0336 - acc: 0.8285 - val_loss: 0.0328 - val_acc: 0.8392\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0335 - acc: 0.8296 - val_loss: 0.0326 - val_acc: 0.8403\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0333 - acc: 0.8306 - val_loss: 0.0325 - val_acc: 0.8412\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0332 - acc: 0.8319 - val_loss: 0.0323 - val_acc: 0.8422\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0330 - acc: 0.8327 - val_loss: 0.0322 - val_acc: 0.8442\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0329 - acc: 0.8337 - val_loss: 0.0320 - val_acc: 0.8450\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0327 - acc: 0.8347 - val_loss: 0.0318 - val_acc: 0.8457\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0326 - acc: 0.8354 - val_loss: 0.0317 - val_acc: 0.8467\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0324 - acc: 0.8363 - val_loss: 0.0315 - val_acc: 0.8478\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0323 - acc: 0.8371 - val_loss: 0.0314 - val_acc: 0.8488\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0321 - acc: 0.8383 - val_loss: 0.0313 - val_acc: 0.8499\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0320 - acc: 0.8391 - val_loss: 0.0311 - val_acc: 0.8508\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0318 - acc: 0.8403 - val_loss: 0.0310 - val_acc: 0.8515\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0317 - acc: 0.8411 - val_loss: 0.0308 - val_acc: 0.8528\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0316 - acc: 0.8419 - val_loss: 0.0307 - val_acc: 0.8531\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0314 - acc: 0.8426 - val_loss: 0.0305 - val_acc: 0.8539\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0313 - acc: 0.8433 - val_loss: 0.0304 - val_acc: 0.8543\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0312 - acc: 0.8442 - val_loss: 0.0303 - val_acc: 0.8552\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0310 - acc: 0.8448 - val_loss: 0.0301 - val_acc: 0.8564\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s - loss: 0.0309 - acc: 0.8453 - val_loss: 0.0300 - val_acc: 0.8568\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0308 - acc: 0.8461 - val_loss: 0.0299 - val_acc: 0.8575\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0306 - acc: 0.8468 - val_loss: 0.0297 - val_acc: 0.8584\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0305 - acc: 0.8475 - val_loss: 0.0296 - val_acc: 0.8589\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0304 - acc: 0.8480 - val_loss: 0.0295 - val_acc: 0.8600\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0302 - acc: 0.8487 - val_loss: 0.0293 - val_acc: 0.8605\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0301 - acc: 0.8496 - val_loss: 0.0292 - val_acc: 0.8610\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0300 - acc: 0.8500 - val_loss: 0.0291 - val_acc: 0.8617\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0299 - acc: 0.8504 - val_loss: 0.0290 - val_acc: 0.8621\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0298 - acc: 0.8510 - val_loss: 0.0289 - val_acc: 0.8625\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0296 - acc: 0.8516 - val_loss: 0.0287 - val_acc: 0.8627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3f3023eb8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=200, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
